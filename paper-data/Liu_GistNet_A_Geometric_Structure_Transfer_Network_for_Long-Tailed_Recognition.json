{
  "arXiv": "http://arxiv.org/abs/2105.00131",
  "title": "GistNet: A Geometric Structure Transfer Network for Long-Tailed Recognition",
  "pdf": "https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_GistNet_A_Geometric_Structure_Transfer_Network_for_Long-Tailed_Recognition_ICCV_2021_paper.pdf",
  "authors": [
    "Bo Liu",
    "Haoxiang Li",
    "Hao Kang",
    "Gang Hua",
    "Nuno Vasconcelos"
  ],
  "abstract": "The problem of long-tailed recognition, where the number of examples per class is highly unbalanced, is considered. It is hypothesized that the well known tendency of standard classifier training to overfit to popular classes can be exploited for effective transfer learning. Rather than eliminating this overfitting, e.g. by adopting popular class-balanced sampling methods, the learning algorithm should instead leverage this overfitting to transfer geometric information from popular to low-shot classes. A new classifier architecture, GistNet, is proposed to support this goal, using constellations of classifier parameters to encode the class geometry. A new learning algorithm is then proposed for GeometrIc Structure Transfer (GIST), with resort to a combination of loss functions that combine class-balanced and random sampling to guarantee that, while overfitting to the popular classes is restricted to geometric parameters, it is leveraged to transfer class geometry from popular to few-shot classes. This enables better generalization for few-shot classes without the need for the manual specification of class weights, or even the explicit grouping of classes into different types. Experiments on two popular long-tailed recognition datasets show that GistNet outperforms existing solutions to this problem.",
  "s2id": "33d5cdbadc95d1ef093104bca9d29c2610fbb5fc",
  "posterSession": "ICCV",
  "citations": 1
}